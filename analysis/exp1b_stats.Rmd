---
title: "Improving memory for and production of singular <i>they</i> pronouns: Experiment 1B"
author: "Bethany Gardner"
date: "03/24/2022, 04/08/2023"
output: 
  pdf_document:
    toc: true
    toc_depth: 3
  github_document:
    toc: true
    toc_depth: 3
editor_options: 
  markdown: 
    wrap: 72
---

```{r}
#| label: exp1b-setup
#| include: false

library(tidyverse)
library(magrittr)
library(insight)
library(lme4)
library(lmerTest)
library(buildmer)

options(dplyr.summarise.inform = FALSE)
```

This is a replication of the first experiment. Everything is identical, except that the production task occurs before the memory task.

# Load Data

Read data, preprocessed from Qualtrics output. See data/exp1b_data_readme for more details.

```{r}
#| label: exp1b-load

exp1b_d_all <- read.csv("data/exp1b_data.csv", stringsAsFactors = TRUE)
str(exp1b_d_all)
```

Set up contrast coding. The first contrast compares they to he+she. The
second contrast compares he to she.

```{r}
#| label: exp1b-contrasts

contrasts(exp1b_d_all$Pronoun) <- cbind(
  "they vs he+she" = c(.33, .33, -.66),
  "he vs she"      = c(-.5, .5, 0)
)
contrasts(exp1b_d_all$Pronoun)
```

Combine pronoun memory and production trials to make one row for each
character.

```{r}
#| label: exp1b-reshape

m_temp <- exp1b_d_all %>%
  filter(M_Type == "pronoun") %>%
  select(SubjID, Name, Pronoun, M_Response, M_Acc)
p_temp <- exp1b_d_all %>%
  filter(!is.na(P_Acc)) %>%
  select(SubjID, Name, Pronoun, P_Pronoun, P_Acc)

exp1b_d <- left_join(m_temp, p_temp, by = c("SubjID", "Name", "Pronoun"))
remove(m_temp, p_temp)

str(exp1b_d)
```

# Memory

### Descriptive Stats

Mean accuracy for all three memory question types.

```{r}
#| label: exp1b-memory-all-means

exp1b_d_all %>%
  filter(!is.na(M_Acc)) %>%
  group_by(M_Type) %>%
  summarise(
    mean = mean(M_Acc) %>% round(2),
    sd   = sd(M_Acc)   %>% round(2)
  )
```

Mean accuracy, split by pronoun type.

```{r}
#| label: exp1b-memory-pronoun-means

exp1b_d %>%
  mutate(Pronoun_Group = ifelse(Pronoun == "they/them", "They", "He + She")) %>%
  group_by(Pronoun_Group) %>%
  summarise(
    mean = mean(M_Acc) %>% round(2),
    sd   = sd(M_Acc)   %>% round(2)
  )
```

96% of participants selected they/them at least once.

```{r}
#| label: exp1b-memory-usedThey

exp1b_r_memory_usedThey <- exp1b_d %>%
  filter(M_Response == "they/them") %>%
  summarise(n = n_distinct(SubjID))

exp1b_r_memory_usedThey / (n_distinct(exp1b_d$SubjID))
```

### Model

Start with model that has random intercepts and slopes for participant
and item. Maximal model has by-participant random intercepts only.

```{r}
#| label: exp1b-memory-model
#| cache: true

exp1b_m_memory <- buildmer(
  formula = M_Acc ~ Pronoun + (1 + Pronoun | SubjID) + (1 + Pronoun | Name),
  data = exp1b_d, family = binomial,
  buildmerControl(direction = "order")
)

summary(exp1b_m_memory)
```

Convert to odds:

```{r}
#| label: exp1b-memory-OR

# intercept (mean)
exp1b_m_memory@model %>% get_intercept() %>% exp()

# they/them vs. he/him + she/her
exp1b_m_memory@model %>%
  get_parameters() %>%
  filter(Parameter == "Pronounthey vs he+she") %>%
  pull(Estimate) %>%
  exp()
```

-   The intercept is significant (p\<.001), such that participants are 2.82 times more likely to answer correctly than incorrectly across all pronoun types.

-   The contrast between they/them and he/him + she/her is significant (p\<.001), such that participants are 5.40 times more likely to get he/him and she/her right than they/them.

-   The contrast between he/him and she/her is not significant.

# Production

### Descriptive Stats

Mean accuracy, split by pronoun type.

```{r}
#| label: exp1b-production-pronoun-means

exp1b_d %>%
  mutate(Pronoun_Group = ifelse(Pronoun == "they/them", "They", "He + She")) %>%
  group_by(Pronoun_Group) %>%
  summarise(
    mean = mean(P_Acc) %>% round(2),
    sd   = sd(P_Acc)   %>% round(2)
  )
```

Responses that did not use a pronoun are infrequent and evenly
distributed across pronoun conditions.

```{r}
#| label: exp1b-production-pronoun-dist

table(exp1b_d$Pronoun, exp1b_d$P_Pronoun)

(exp1b_d %>% filter(P_Pronoun == "none") %>% pull(P_Pronoun) %>% length()) /
(exp1b_d %>% pull(P_Pronoun) %>% length())
```

71% of participants produced they/them at least once.

```{r}
#| label: exp1b-production-usedThey

exp1b_r_prod_usedThey <- exp1b_d %>%
  filter(P_Pronoun == "they/them") %>%
  summarize(n = n_distinct(SubjID))

exp1b_r_prod_usedThey / (n_distinct(exp1b_d$SubjID))
```

### Model

Start with model that has random intercepts and slopes for participant
and item, using same specifications as before. Maximal model has random
intercepts by participant and item, and no random slopes.

```{r}
#| label: exp1b-production-model
#| cache: true

exp1b_m_prod <- buildmer(
  formula = P_Acc ~ Pronoun + (1 + Pronoun | SubjID) + (1 + Pronoun | Name),
  data = exp1b_d, family = binomial,
  buildmerControl(direction = "order")
)

summary(exp1b_m_prod)
```

Convert to odds:

```{r}
#| label: exp1b-production-OR

# intercept (mean)
exp1b_m_prod@model %>% get_intercept() %>% exp()

# they/them vs. he/him + she/her
exp1b_m_prod@model %>%
  get_parameters() %>%
  filter(Parameter == "Pronounthey vs he+she") %>%
  pull(Estimate) %>%
  exp()
```

-   The intercept is significant (p\<.001), such that participants are 3.03 times more likely to answer correctly than incorrectly across all pronoun types.

-   The contrast between they/them and he/him + she/her is significant (p\<.001), such that participants are 11.90 times more likely to get he/him and she/her right than they/them.

-   The contrast between he/him and she/her is not significant.

# Memory Predicting Production

### Descriptive Stats

Accuracy for producing they/them is lower than accuracy for remembering they/them. But for he/him and she/her, production accuracy is higher.

```{r}
#| label: exp1b-compare-means

exp1b_d %>%
  pivot_longer(
    cols      = c(M_Acc, P_Acc),
    names_to  = "Task",
    values_to = "Acc"
  ) %>%
  group_by(Pronoun, Task) %>%
  summarise(mean = mean(Acc) %>% round(2))
```

Combining the two measures, there are 4 possible patterns: getting both right, getting both wrong, getting just memory right, and getting just production right.

```{r}
#| label: exp1b-mp-dist

exp1b_d %<>% mutate(
  Combined_Accuracy = case_when(
    M_Acc == 1 & P_Acc == 1 ~ "Both right",
    M_Acc == 0 & P_Acc == 0 ~ "Both wrong",
    M_Acc == 1 & P_Acc == 0 ~ "Memory only",
    M_Acc == 0 & P_Acc == 1 ~ "Production only"
  )
)

exp1b_d %>%
  group_by(Pronoun, Combined_Accuracy) %>%
  summarise(n = n())
```

Production accuracy for they/them when memory was correct vs incorrect.

```{r}
#| label: exp1b-mp-split

exp1b_d %>%
  filter(Pronoun == "they/them") %>%
  group_by(M_Acc, Pronoun) %>%
  summarise(P_Acc = mean(P_Acc) %>% round(2))
```

### Model

Create factor for Memory Accuracy that is mean-center effects coded,
comparing incorrect to correct.

```{r}
#| label: exp1b-mean-center-acc

exp1b_d %<>% mutate(M_Acc_Factor = as.factor(M_Acc))
contrasts(exp1b_d$M_Acc_Factor) <- cbind("wrong vs right" = c(-0.5, +0.5))
contrasts(exp1b_d$M_Acc_Factor)
```


```{r}
#| label: exp1b-mp-model-buildmer
#| cache: true

exp1b_m_mp_buildmer <- buildmer(
  formula = P_Acc ~ M_Acc_Factor * Pronoun +
    (Pronoun * M_Acc_Factor | SubjID) + (M_Acc_Factor * Pronoun | Name),
  data = exp1b_d, family = binomial,
  buildmerControl(direction = "order")
)

summary(exp1b_m_mp_buildmer)
```

buildmer doesn't include any random effects, which is odd. Here I'm starting by adding back the by-subject random intercepts (based on that having the larger variance in the production model).

```{r}
#| label: exp1b-mp-model-subj-intercepts
#| cache: true

exp1b_m_mp_subjInt <- glmer(
  formula = P_Acc ~ M_Acc_Factor * Pronoun + (1 | SubjID),
  data = exp1b_d, family = binomial
)
summary(exp1b_m_mp_subjInt)

exp1b_opt_subjInt <- allFit(exp1b_m_mp_subjInt)
summary(exp1b_opt_subjInt)
```

Most of the optimizers are throwing convergence errors, and all of the estimates are very consistent across optimizers. But the z values are weird and you shouldn't get identical SEs, so the errors aren't ok to ignore.

Check by-item intercepts:

```{r}
#| label: exp1b-mp-model-item-intercepts
#| cache: true

exp1b_m_mp_itemInt <- glmer(
  formula = P_Acc ~ M_Acc_Factor * Pronoun + (1 | Name),
  data = exp1b_d, family = binomial
)
summary(exp1b_m_mp_itemInt)

exp1b_opt_itemInt <- allFit(exp1b_m_mp_itemInt)
summary(exp1b_opt_itemInt)
```

The by-item intercept model isn't giving impossible results, but two of the optimizers have very different estimates for the random intercepts than the rest of them, so let's just stick with the original model:

```{r}
#| label: exp1b-mp-model-results

summary(exp1b_m_mp_buildmer)

# memory accuracy
exp1b_m_mp_buildmer@model %>%
  get_parameters() %>%
  filter(Parameter == "M_Acc_Factorwrong vs right") %>%
  pull(Estimate) %>%
  exp()

# they/them vs. he/him + she/her * memory accuracy
exp1b_m_mp_buildmer@model %>%
  get_parameters() %>%
  filter(Parameter == "Pronounthey vs he+she:M_Acc_Factorwrong vs right") %>%
  pull(Estimate) %>%
  exp()
```

-   The effect of memory accuracy is significant (p\<.001), such that participants are 4.44x more likely to get the production right if they got the memory right.

-   Significant interaction between pronoun type (they/them vs. he/him + she/her) and memory accuracy (p\<.05) (odds 0.31). The relative difficulty of they/them was attenuated when the participant had correctly remembered the character's pronoun during the memory phase of the task.

# Job/Pet

```{r}
#| label: exp1b-job-means

exp1b_d_all %>%
  filter(M_Type == "job") %>%
  group_by(Pronoun) %>%
  summarise(
    mean = mean(M_Acc) %>% round(2),
    sd   = sd(M_Acc)   %>% round(2)
  )
```


```{r}
#| label: exp1b-pet-means

exp1b_d_all %>%
  filter(M_Type == "pet") %>%
  group_by(Pronoun) %>%
  summarise(
    mean = mean(M_Acc) %>% round(2),
    sd   = sd(M_Acc)   %>% round(2)
  )
```

Compare pet accuracy to pronoun accuracy. Pronoun (renamed to Character Pronoun here for clarity) stays contrast coded as before, and Question Type (M_Type = pet or pronoun) is mean-center effects coded, comparing pet questions to pronoun questions.

```{r}
#| label: exp1b-compare-all-means

exp1b_d_pronounsPets <- exp1b_d_all %>%
  filter(M_Type == "pet" | M_Type == "pronoun") %>%
  rename("CharPronoun" = "Pronoun")

exp1b_d_pronounsPets$M_Type %<>% droplevels()
contrasts(exp1b_d_pronounsPets$M_Type) <- cbind(
  "petQ vs pronounQ" = c(-.5, .5))
contrasts(exp1b_d_pronounsPets$M_Type)
```

```{r}
#| label: exp1b-compare-pets-model
#| cache: true

exp1b_m_pet <- buildmer(
  formula = M_Acc ~ CharPronoun * M_Type +
            (M_Type * CharPronoun | SubjID) +
            (M_Type * CharPronoun | Name),
  data = exp1b_d_pronounsPets, family = binomial,
  buildmerControl(direction = "order"))

summary(exp1b_m_pet)
```

-   Like in main experiment:
-   Significant main effect of Question Type (p\<.001), with higher accuracy for pronouns
-   Significant interaction between Pronoun and Question Type, such that the difference between Question Types is larger for he/him + she/her questions than for they/them characters.

To check this interaction direction, dummy coded Pronoun with they/them characters as 0 and he/him and she/her characters as 1

```{r}
#| label: exp1b-compare-pets-model-they0
#| cache: true

exp1b_d_pronounsPets %<>% mutate(CharPronoun_They0 = ifelse(
  CharPronoun == "they/them", 0, 1))

exp1b_m_pet_they <- glmer(
  formula = M_Acc ~ CharPronoun_They0 * M_Type + (M_Type | SubjID),
  data = exp1b_d_pronounsPets, family = binomial,
)

summary(exp1b_m_pet_they)
```

-   Only trending (p = .064) main effect of Question Type (M_Type) means that there is no difference between pet and pronoun questions when Pronoun is 0 (= for they/them characters).

Now dummy code to get main effect of Question Type in he/him + she/her (= 0)

```{r}
#| label: exp1-compare-pets-model-heshe0
#| cache: true

exp1b_d_pronounsPets %<>% mutate(CharPronoun_HeShe0 = ifelse(
  CharPronoun == "they/them", 1, 0))

exp1b_m_pet_heshe <- glmer(
  formula = M_Acc ~ CharPronoun_HeShe0 * M_Type + (M_Type | SubjID),
  data = exp1b_d_pronounsPets, family = binomial,
)

summary(exp1b_m_pet_heshe)
```

-   Like in main experiment, significant (p \< .001) main effect of Question Type (M_Type) means that pronoun questions were more accurate than pet questions for he/him + she/her characters

### Task Difference

Difference score between memory and production for each pronoun for each participant

```{r}
#| label: exp1-compare-diff-means

# calculate difference between memory and production accuracy for each
# participant for they/them characters
exp1_d_diff <- exp1_d %>%
  group_by(Experiment, SubjID, Pronoun) %>%
  summarise(
    M_Acc = mean(M_Acc),
    P_Acc = mean(P_Acc),
    Diff  = M_Acc - P_Acc
  ) %>%
  ungroup()
summary(exp1_d_diff)
```

```{r}
#| label: exp1-compare-diff-model

# simple lm with diff as outcome
exp1_m_diff <- lm(
  formula = Diff ~ Experiment * Pronoun,
  data = exp1_d_diff
)

summary(exp1_m_diff)
```

-   No main effect of experiment
-   No interactions with pronoun


