---
title: "Improving memory for and production of singular <i>they</i> pronouns: Experiment 1B"
author: "Bethany Gardner"
date: "03/24/2022"
output: 
  github_document:
    toc: true
    toc_depth: 3
  pdf_document:
    toc: true
    toc_depth: 3
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(magrittr)
library(lmerTest)
library(buildmer)
library(sjmisc)
```

This is a replication of the first experiment. Everything is identical,
except that the production task occurs before the memory task.

# Load Data

Read data, preprocessed from Qualtrics output. See
data/exp1b_data_readme for more details.

```{r}
d <- read.csv("../data/exp1b_data.csv", stringsAsFactors=TRUE)
str(d)
```

Set up contrast coding. The first contrast compares they to he+she. The
second contrast compares he to she.

```{r}
contrasts(d$Pronoun) = cbind("they vs he+she"=c(.33,.33,-.66), 
                             "he vs she"=c(-.5,.5, 0))
contrasts(d$Pronoun)
```

Split data by task, and only keep pronoun questions (not the job or pet
questions) in memory dataframe.

```{r}
m <- d %>% filter(M_Type=="pronoun")
p <- d %>% filter(Task=="production")
```

Combine memory and production trials to make one row for each character.

```{r}
#Get pronoun memory and production observations. Filter out memory for job and pet questions, and introduction pilot task questions.
mp <- d %>% filter(Task != "introduction" & 
                   M_Type != "job" &
                   M_Type != "pet") 

#Just take columns used in model
m_temp <- mp %>% select(M_Acc, Pronoun, Name, SubjID) %>%
  filter(!is.na(M_Acc)) #Take out empty rows that were other question types

#Get production accuracy column
p_temp <- mp %>% select(P_Acc)  %>%
    filter(!is.na(P_Acc)) #Take out empty rows that were other question types

#Combine
mp <- cbind(m_temp, p_temp) 
str(mp)
```

# Memory

### Descriptive Stats

Mean accuracy for all three memory question types.

```{r}
prop.table(table(d$M_Type, d$M_Acc), margin=1)
```

Mean accuracy, split by pronoun type.

```{r}
prop.table(table(m$Pronoun, m$M_Acc), margin=1)
```

96% of participants selected they/them at least once.

```{r}
they_m <- d %>% filter(M_Response=="they/them") %>%
  summarize(n=n_distinct(SubjID)) 

they_m/(n_distinct(d$SubjID))

```

### Model

Start with model that has random intercepts and slopes for participant
and item. Maximal model has by-participant random intercepts only.

```{r}
model_m_full <- M_Acc ~ Pronoun + (1 + Pronoun|SubjID) + (1 + Pronoun|Name)

model_m <- buildmer(model_m_full, data=m, 
                    family='binomial', direction=c('order'))
summary(model_m)
```

Convert to odds:

```{r}
exp(0.94930) #intercept (mean)
exp(1.55205) #they/them vs. he/him + she/her
```

-   The intercept is significant (p\<.001), such that participants are
    2.58 times more likely to answer correctly than incorrectly across
    all pronoun types.

-   The contrast between they/them and he/him + she/her is significant
    (p\<.001), such that participants are 4.72 times more likely to get
    he/him and she/her right than they/them.

-   The contrast between he/him and she/her is not significant.

# Production

### Descriptive Stats

Mean accuracy, split by pronoun type. Accuracy for producing they/them
is lower than accuracy for remembering they/them.

```{r}
prop.table(table(p$Pronoun, p$P_Acc), margin=1)
```

71% of participants produced they/them at least once.

```{r}
they_p <- d %>% filter(P_Pronoun=="they/them") %>%
  summarize(n=n_distinct(SubjID)) 

they_p/(n_distinct(d$SubjID))

```

### Model

Start with model that has random intercepts and slopes for participant
and item, using same specifications as before. Maximal model has random
intercepts by participant and item, and no random slopes.

```{r}
model_p_full <- P_Acc ~ Pronoun + 
  (1 + Pronoun|SubjID) + (1 + Pronoun|Name)

model_p <- buildmer(model_p_full, data=p, 
          family='binomial', direction=c('order'))
summary(model_p)
```

Convert to odds:

```{r}
exp(1.10833) #intercept (mean)
exp(2.476427) #they/them vs. he/him + she/her
```

-   The intercept is significant (p\<.001), such that participants are
    3.02 times more likely to answer correctly than incorrectly across
    all pronoun types.

-   The contrast between they/them and he/him + she/her is significant
    (p\<.001), such that participants are 11.83 times more likely to get
    he/him and she/her right than they/them.

-   The contrast between he/him and she/her is not significant.

# Memory Predicting Production

### Descriptive Stats

Combining the two measures, there are 4 possible patterns: getting both
right, getting both wrong, getting just memory right, and getting just
production right.

```{r}
mp_acc <- mp %>% 
          mutate(BothRight=ifelse(M_Acc==1 & P_Acc==1, 1, 0)) %>%
          mutate(BothWrong=ifelse(M_Acc==0 & P_Acc==0, 1, 0)) %>%
          mutate(MemOnly=ifelse(M_Acc==1 & P_Acc==0, 1, 0)) %>%
          mutate(ProdOnly=ifelse(M_Acc==0 & P_Acc==1, 1, 0)) %>%
          pivot_longer(cols=c(BothRight, BothWrong, MemOnly, ProdOnly),
                       names_to="Combined_Accuracy") %>%
          group_by(Pronoun, Combined_Accuracy) %>%
          summarise(m=mean(value))
mp_acc
```

### Model

Create factor for Memory Accuracy that is mean-center effects coded,
comparing incorrect to correct.

```{r}
#| label: exp1b-mean-center-acc

exp1b_d %<>% mutate(M_Acc_Factor = as.factor(M_Acc))
contrasts(exp1b_d$M_Acc_Factor) <- cbind("wrong vs right" = c(-0.5, +0.5))
contrasts(exp1b_d$M_Acc_Factor)
```


```{r}
#| label: exp1b-mp-model-buildmer
#| cache: true

exp1b_m_mp_buildmer <- buildmer(
  formula = P_Acc ~ M_Acc_Factor * Pronoun +
    (Pronoun * M_Acc_Factor | SubjID) + (M_Acc_Factor * Pronoun | Name),
  data = exp1b_d, family = binomial,
  buildmerControl(direction = "order")
)

summary(exp1b_m_mp_buildmer)
```

buildmer doesn't include any random effects, which is odd. Here I'm starting by adding back the by-subject random intercepts (based on that having the larger variance in the production model).

```{r}
#| label: exp1b-mp-model-subj-intercepts
#| cache: true

exp1b_m_mp_subjInt <- glmer(
  formula = P_Acc ~ M_Acc_Factor * Pronoun + (1 | SubjID),
  data = exp1b_d, family = binomial
)
summary(exp1b_m_mp_subjInt)

exp1b_opt_subjInt <- allFit(exp1b_m_mp_subjInt)
summary(exp1b_opt_subjInt)
```

Most of the optimizers are throwing convergence errors, and all of the estimates are very consistent across optimizers. But the z values are weird and you shouldn't get identical SEs, so the errors aren't ok to ignore.

Check by-item intercepts:

```{r}
#| label: exp1b-mp-model-item-intercepts
#| cache: true

exp1b_m_mp_itemInt <- glmer(
  formula = P_Acc ~ M_Acc_Factor * Pronoun + (1 | Name),
  data = exp1b_d, family = binomial
)
summary(exp1b_m_mp_itemInt)

exp1b_opt_itemInt <- allFit(exp1b_m_mp_itemInt)
summary(exp1b_opt_itemInt)
```

The by-item intercept model isn't giving impossible results, but two of the optimizers have very different estimates for the random intercepts than the rest of them, so let's just stick with the original model:

```{r}
#| label: exp1b-mp-model-results

summary(exp1b_m_mp_buildmer)

# memory accuracy
exp1b_m_mp_buildmer@model %>%
  get_parameters() %>%
  filter(Parameter == "M_Acc_Factorwrong vs right") %>%
  pull(Estimate) %>%
  exp()

# they/them vs. he/him + she/her * memory accuracy
exp1b_m_mp_buildmer@model %>%
  get_parameters() %>%
  filter(Parameter == "Pronounthey vs he+she:M_Acc_Factorwrong vs right") %>%
  pull(Estimate) %>%
  exp()
```

-   The effect of memory accuracy is significant (p\<.001), such that participants are 4.44x more likely to get the production right if they got the memory right.

-   Significant interaction between pronoun type (they/them vs. he/him + she/her) and memory accuracy (p\<.05) (odds 0.31). The relative difficulty of they/them was attenuated when the participant had correctly remembered the character's pronoun during the memory phase of the task.

# Job/Pet

```{r}
#| label: exp1b-job-means

exp1b_d_all %>%
  filter(M_Type == "job") %>%
  group_by(Pronoun) %>%
  summarise(
    mean = mean(M_Acc) %>% round(2),
    sd   = sd(M_Acc)   %>% round(2)
  )
```


```{r}
#| label: exp1b-pet-means

exp1b_d_all %>%
  filter(M_Type == "pet") %>%
  group_by(Pronoun) %>%
  summarise(
    mean = mean(M_Acc) %>% round(2),
    sd   = sd(M_Acc)   %>% round(2)
  )
```

Compare pet accuracy to pronoun accuracy. Pronoun (renamed to Character Pronoun here for clarity) stays contrast coded as before, and Question Type (M_Type = pet or pronoun) is mean-center effects coded, comparing pet questions to pronoun questions.

```{r}
#| label: exp1b-compare-all-means

exp1b_d_pronounsPets <- exp1b_d_all %>%
  filter(M_Type == "pet" | M_Type == "pronoun") %>%
  rename("CharPronoun" = "Pronoun")

exp1b_d_pronounsPets$M_Type %<>% droplevels()
contrasts(exp1b_d_pronounsPets$M_Type) <- cbind(
  "petQ vs pronounQ" = c(-.5, .5))
contrasts(exp1b_d_pronounsPets$M_Type)
```

```{r}
#| label: exp1b-compare-pets-model
#| cache: true

exp1b_m_pet <- buildmer(
  formula = M_Acc ~ CharPronoun * M_Type +
            (M_Type * CharPronoun | SubjID) +
            (M_Type * CharPronoun | Name),
  data = exp1b_d_pronounsPets, family = binomial,
  buildmerControl(direction = "order"))

summary(exp1b_m_pet)
```

-   Like in main experiment:
-   Significant main effect of Question Type (p\<.001), with higher accuracy for pronouns
-   Significant interaction between Pronoun and Question Type, such that the difference between Question Types is larger for he/him + she/her questions than for they/them characters.

To check this interaction direction, dummy coded Pronoun with they/them characters as 0 and he/him and she/her characters as 1

```{r}
#| label: exp1b-compare-pets-model-they0
#| cache: true

exp1b_d_pronounsPets %<>% mutate(CharPronoun_They0 = ifelse(
  CharPronoun == "they/them", 0, 1))

exp1b_m_pet_they <- glmer(
  formula = M_Acc ~ CharPronoun_They0 * M_Type + (M_Type | SubjID),
  data = exp1b_d_pronounsPets, family = binomial,
)

summary(exp1b_m_pet_they)
```

-   Only trending (p = .064) main effect of Question Type (M_Type) means that there is no difference between pet and pronoun questions when Pronoun is 0 (= for they/them characters).

Now dummy code to get main effect of Question Type in he/him + she/her (= 0)

```{r}
#| label: exp1-compare-pets-model-heshe0
#| cache: true

exp1b_d_pronounsPets %<>% mutate(CharPronoun_HeShe0 = ifelse(
  CharPronoun == "they/them", 1, 0))

exp1b_m_pet_heshe <- glmer(
  formula = M_Acc ~ CharPronoun_HeShe0 * M_Type + (M_Type | SubjID),
  data = exp1b_d_pronounsPets, family = binomial,
)

summary(exp1b_m_pet_heshe)
```

-   Like in main experiment, significant (p \< .001) main effect of Question Type (M_Type) means that pronoun questions were more accurate than pet questions for he/him + she/her characters


-   Significant interaction between pronoun type (they/them vs. he/him +
    she/her) and memory accuracy (p\<.05) (odds 0.31). The relative
    difficulty of they/them was attenuated when the participant had
    correctly remembered the character's pronoun during the memory phase
    of the task.
